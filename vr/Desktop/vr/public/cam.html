<!--
To change this template, choose Tools | Templates
and open the template in the editor.
-->
<!DOCTYPE html>
<html>
    <head>
    <script type="text/javascript" src="http://code.jquery.com/jquery-2.0.3.min.js"></script>

    <script>

    navigator.getUserMedia = ( navigator.getUserMedia ||
                               navigator.webkitGetUserMedia ||
                               navigator.mozGetUserMedia ||
                               navigator.msGetUserMedia);


    window.AudioContext = (function(){
        return  window.webkitAudioContext || window.AudioContext || window.mozAudioContext;
    })();

    var leftchannel = [];
    var rightchannel = [];
    var recordingLength = 0;

    // Global Variables for Audio
    var audioContext;
    var analyserNode;
    var javascriptNode;
    // max is 16384
    var sampleSize = 16384;  // number of samples to collect before analyzing
                            // decreasing this gives a faster sonogram, increasing it slows it down

    var sampleRate = 44100 ; // 這個似乎是固定的
    var enableAudio = true ;
    var amplitudeArray;     // array to hold frequency data
    var audioStream;

    var fps = 1000 / 10 ;
    var videoWidth = 640 ;
    var videoHeight = 480 ;
    var jpegQ = 50 ;

  	var name = "ipcam" + Math.floor((Math.random() * 900) + 100);
  	var back = document.createElement('canvas');
  	var backcontext = back.getContext('2d');
  	var videoCount = 0 ;
    var audioCount = 0 ;

  	var img ;
  	var ws;

    function connect(host) {
        ws = new WebSocket(host);
        ws.onopen = function () {
            console.log('connected');
        }

        ws.onclose = function () {
  	      alert('socket closed @@');
            console.log('closed');
        }

        ws.onerror = function(evt) {
            console.log('<span style="color: red;"> websocket ERROR:</span> ' + evt.data);
             alert('socket error ed @@');
        }
    }

    function send(msg) {
        if (ws != null) {
            if (ws.readyState === 1)
			{
                ws.send(msg) ;
			}
			else {
				console.log("readyState = " + ws.readyState)
			}
        } else {
            console.log('not ready yet');
        }
    }

    function hasGetUserMedia() {
		return !!(navigator.getUserMedia || navigator.webkitGetUserMedia ||
            navigator.mozGetUserMedia || navigator.msGetUserMedia);
	}



	function draw(v, bc, w, h) {
		bc.drawImage(v, 0, 0, w, h);

		var stringData = back.toDataURL("image/jpeg", jpegQ );

		// img.src = stringData ;
		var now = new Date();

		//send( str ) ;
    videoCount = videoCount + 1 ;
		var arr = { name: name, msg: "count=" + videoCount + "/" + audioCount , video: stringData, tt: new Date().getTime() } ;
		//console.log( str )
		$("div#log").text( arr.msg ) ;
		send( JSON.stringify( arr ) );

		//console.log( "send one data" ) ;
		setTimeout(function() { draw(v, bc, w, h) }, fps);
	}



function setupAudioNodes(stream) {
      // create the media stream from the audio input source (microphone)
      sourceNode = audioContext.createMediaStreamSource(stream);
      audioStream = stream;

      analyserNode   = audioContext.createAnalyser();
      javascriptNode = audioContext.createScriptProcessor(sampleSize, 1, 1);

      // Create the array for the data values
      amplitudeArray = new Uint8Array(analyserNode.frequencyBinCount);

      // setup the event handler that is triggered every time enough samples have been collected
      // trigger the audio analysis and draw one column in the display based on the results
      javascriptNode.onaudioprocess = function (e) {
        var left = e.inputBuffer.getChannelData (0);
        //var right = e.inputBuffer.getChannelData (1);
        // we clone the samples
        leftchannel.push (new Float32Array (left));
        //rightchannel.push (new Float32Array (right));
        recordingLength += sampleSize;
        //console.log('recording len=' + recordingLength );


        if ( recordingLength > 60000 ) {
          sendBuffer() ;
        }
          //
          // console.log(" on audio process XXD") ;
          // amplitudeArray = new Uint8Array(analyserNode.frequencyBinCount);
          // analyserNode.getByteTimeDomainData(amplitudeArray);

          // draw one column of the display
          //requestAnimFrame(drawTimeDomain);
      }

      // Now connect the nodes together
      // Do not connect source node to destination - to avoid feedback
      sourceNode.connect(analyserNode);
      analyserNode.connect(javascriptNode);
      javascriptNode.connect(audioContext.destination);
}

function writeUTFBytes(view, offset, string){
  var lng = string.length;
  for (var i = 0; i < lng; i++){
    view.setUint8(offset + i, string.charCodeAt(i));
  }
}


var sendBuffer = function () {
    console.log("send buffer start") ;
    //var outputElement = document.getElementById('output');
    // we flat the left and right channels down
    var leftBuffer = mergeBuffers ( leftchannel, recordingLength );
    //var rightBuffer = mergeBuffers ( rightchannel, recordingLength );

    leftchannel = [] ;
    recordingLength = 0 ;
    // we interleave both channels together
    var interleaved = leftBuffer ;

    // we create our wav file
    var buffer = new ArrayBuffer(48 + interleaved.length * 2);
    var view = new DataView(buffer);

    // RIFF chunk descriptor
    writeUTFBytes(view, 0, 'RIFF');
    view.setUint32(4, 32 + interleaved.length * 2, true);
    writeUTFBytes(view, 8, 'WAVE');
    // FMT sub-chunk
    writeUTFBytes(view, 12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    // stereo (2 channels)
    view.setUint16(22, 1, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * 2, true);
    view.setUint16(32, 2, true);
    view.setUint16(34, 16, true);



    /*
    1 - 4	"RIFF"	Marks the file as a riff file. Characters are each 1 byte long.
    5 - 8	File size (integer)	Size of the overall file - 8 bytes, in bytes (32-bit integer). Typically, you'd fill this in after creation.
    9 -12	"WAVE"	File Type Header. For our purposes, it always equals "WAVE".
    13-16	"fmt "	Format chunk marker. Includes trailing null
    17-20	16	Length of format data as listed above
    21-22	1	Type of format (1 is PCM) - 2 byte integer
    23-24	2	Number of Channels - 2 byte integer
    25-28	44100	Sample Rate - 32 byte integer. Common values are 44100 (CD), 48000 (DAT). Sample Rate = Number of Samples per second, or Hertz.
    29-32	176400	(Sample Rate * BitsPerSample * Channels) / 8.
    33-34	4	(BitsPerSample * Channels) / 8.1 - 8 bit mono2 - 8 bit stereo/16 bit mono4 - 16 bit stereo
    35-36	16	Bits per sample
    37-40	"data"	"data" chunk header. Marks the beginning of the data section.
    41-44	File size (data)	Size of the data section.
*/



    // data sub-chunk
    writeUTFBytes(view, 36, 'data');
    view.setUint32(40, interleaved.length * 2, true);

    floatTo16BitPCM(view, 44, interleaved);
    // write the PCM samples

    /*
    var lng = interleaved.length;
    var index = 44;
    var volume = 5;
    for (var i = 0; i < lng; i++){
        view.setInt16(index, interleaved[i] * (0x7FFF * volume), true);
        index += 2;
    }
    */



    // our final binary blob
    var blob = new Blob ( [ view ], { type : 'audio/wav' } );

    // let's save it locally
    var url = (window.URL || window.webkitURL).createObjectURL(blob);
    // copy this object and send ~~


    /*
    var link = window.document.createElement('a');
    link.href = url;
    link.download = 'output.wav';
    var click = document.createEvent("Event");
    click.initEvent("click", true, true);
    link.dispatchEvent(click);
    */
		var now = new Date();
		var str = "audio at " + new Date().toISOString() ;

		//console.log( str )
    var reader = new window.FileReader();
    reader.readAsDataURL(blob);
    reader.onloadend = function() {
        base64data = reader.result;

        audioCount = audioCount + 1 ;
        var arr = { name: name, msg:  "count=" + videoCount + "/" + audioCount , audio: base64data, tt: new Date().getTime() } ;
        send( JSON.stringify( arr ) );
        //console.log(base64data );
    }
		$("div#log").text(str) ;


}

function floatTo16BitPCM(output, offset, input){
  for (var i = 0; i < input.length; i++, offset+=2){
    var s = Math.max(-1, Math.min(1, input[i]));
    output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
  }
}

function mergeBuffers(channelBuffer, recordingLength){
  var result = new Float32Array(recordingLength);
  var offset = 0;
  var lng = channelBuffer.length;
  for (var i = 0; i < lng; i++){
    var buffer = channelBuffer[i];
    result.set(buffer, offset);
    offset += buffer.length;
  }
  return result;
}


var mobilecheck = function() {
  var check = false;
  (function(a){if(/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(a)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(a.substr(0,4)))check = true})(navigator.userAgent||navigator.vendor||window.opera);
  return check;
}


var getDT = function () {
  var str = new Date().toISOString() ;
  str = str.replace( "T", " ") ;
  str = str.replace( "Z", "") ;
  return str ;

}

$(function(){
	$("span.name").text("client name=" + name ) ;


  if ( mobilecheck() ) {
    fps = 1000 / 10;
    enableAudio = true ; // 關掉 因為隻手機都都在吹狗縲
    name = "Mobile_" + name ;
    videoWidth = 640 ;
    videoHeight = 480 ;
    jpegQ = 50 ;
  }

  $("video").css("width", videoWidth ) ;
  $("video").css("height", videoHeight ) ;

  try {
      audioContext = new AudioContext();
  } catch(e) {
      alert('Web Audio API is not supported in this browser');
  }

	var video = document.getElementById('sourcevid');


	navigator.getMedia = ( navigator.getUserMedia ||
						   navigator.webkitGetUserMedia ||
						   navigator.mozGetUserMedia ||
						   navigator.msGetUserMedia);

	if (hasGetUserMedia()) {
		navigator.getMedia(
			{video: true, audio: enableAudio},
			function (localMediaStream) {
				video.src = window.URL.createObjectURL(localMediaStream);

				console.log( JSON.stringify(video) ) ;
				cw = video.clientWidth;
				ch = video.clientHeight;
				back.width = cw;
				back.height = ch;
				console.log( "get width = " + cw + "," + ch ) ;
				$("div#id").text( "get width = " + cw + "," + ch ) ;
				img = document.getElementById('sended');
				draw(video, backcontext, cw, ch);

        setupAudioNodes(localMediaStream) ;


			},
			function (e) {
				console.log(e);
			}
		);



		if ('WebSocket' in window) {
			connect('ws://' + window.location.hostname + ':8081/');
		} else {
			console.log('web sockets not suported');
			alert('getUserMedia() is not supported in your browser!');
		}

	} else {
		alert('getUserMedia() is not supported in your browser!');
	}
}) ;


    </script>

    <style>
    	video {
    		width: 320px ;
    		height: 240px ;
    	}
    </style>
        <title></title>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    </head>
    <body>
        <div>
            <h1>實踐家58 - 全民大搜證</h1>
            <video autoplay id="sourcevid" ></video>
            <canvas id="output"></canvas>
        </div>
        <BR>
        <span class="name"></span>
        <div id="log"></div>
		<div>
		<img src="" id="sended" style="">
		</div>

    </body>
</html>
